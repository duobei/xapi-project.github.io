<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Features on XAPI Toolstack Developer Documentation</title><link>https://xapi-project.github.io/new-docs/toolstack/features/index.html</link><description>Recent content in Features on XAPI Toolstack Developer Documentation</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://xapi-project.github.io/new-docs/toolstack/features/index.xml" rel="self" type="application/rss+xml"/><item><title>Disaster Recovery</title><link>https://xapi-project.github.io/new-docs/toolstack/features/DR/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://xapi-project.github.io/new-docs/toolstack/features/DR/index.html</guid><description>The HA feature will restart VMs after hosts have failed, but what happens if a whole site (e.g. datacenter) is lost? A disaster recovery configuration is shown in the following diagram:
We rely on the storage array&amp;rsquo;s built-in mirroring to replicate (synchronously or asynchronously: the admin&amp;rsquo;s choice) between the primary and the secondary site. When DR is enabled the VM disk data and VM metadata are written to the storage server and mirrored.</description></item><item><title>High-Availability</title><link>https://xapi-project.github.io/new-docs/toolstack/features/HA/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://xapi-project.github.io/new-docs/toolstack/features/HA/index.html</guid><description>High-Availability (HA) tries to keep VMs running, even when there are hardware failures in the resource pool, when the admin is not present. Without HA the following may happen:
during the night someone spills a cup of coffee over an FC switch; then VMs running on the affected hosts will lose access to their storage; then business-critical services will go down; then monitoring software will send a text message to an off-duty admin; then the admin will travel to the office and fix the problem by restarting the VMs elsewhere.</description></item><item><title>Snapshots</title><link>https://xapi-project.github.io/new-docs/toolstack/features/snapshots/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://xapi-project.github.io/new-docs/toolstack/features/snapshots/index.html</guid><description>Snapshots represent the state of a VM, or a disk (VDI) at a point in time. They can be used for:
backups (hourly, daily, weekly etc) experiments (take snapshot, try something, revert back again) golden images (install OS, get it just right, clone it 1000s of times) Read more about the Snapshot APIs.
Disk snapshots Disks are represented in the XenAPI as VDI objects. Disk snapshots are represented as VDI objects with the flag is_a_snapshot set to true.</description></item><item><title>vGPU</title><link>https://xapi-project.github.io/new-docs/toolstack/features/VGPU/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://xapi-project.github.io/new-docs/toolstack/features/VGPU/index.html</guid><description>XenServer has supported passthrough for GPU devices since XenServer 6.0. Since the advent of NVIDIA&amp;rsquo;s vGPU-capable GRID K1/K2 cards it has been possible to carve up a GPU into smaller pieces yielding a more scalable solution to boosting graphics performance within virtual machines.
The K1 has four GK104 GPUs and the K2 two GK107 GPUs. Each of these will be exposed through Xapi so a host with a single K1 card will have access to four independent PGPUs.</description></item><item><title>Xapi Storage Migration</title><link>https://xapi-project.github.io/new-docs/toolstack/features/XSM/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://xapi-project.github.io/new-docs/toolstack/features/XSM/index.html</guid><description>The Xapi Storage Migration (XSM) also known as &amp;ldquo;Storage Motion&amp;rdquo; allows
a running VM to be migrated within a pool, between different hosts and different storage simultaneously; a running VM to be migrated to another pool; a disk attached to a running VM to be moved to another SR. The following diagram shows how XSM works at a high level:
The slowest part of a storage migration is migrating the storage, since virtual disks can be very large.</description></item></channel></rss>